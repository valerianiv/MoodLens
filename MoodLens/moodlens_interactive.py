import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import cv2
import numpy as np
from PIL import Image, ImageTk
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import os
from datetime import datetime
import json
import uuid
from mediapipe.python.solutions import face_detection
class EmotionRecognitionApp:
    def __init__(self, root):
        self.root = root
        self.root.title("MoodLens - –°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —ç–º–æ—Ü–∏–π")
        self.root.geometry("1400x900")
        self.root.configure(bg='#2c3e50')

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–∫–æ–Ω–∫–∏
        try:
            icon_path = os.path.join(os.path.dirname(__file__), 'icon.png')
            if os.path.exists(icon_path):
                icon = ImageTk.PhotoImage(Image.open(icon_path).resize((32, 32)))
                self.root.iconphoto(True, icon)
        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∫–æ–Ω–∫—É: {e}")
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self.image_path = None
        self.original_image = None
        self.processed_image = None
        self.face_bboxes = []
        self.current_face_index = -1
        self.emotion_results = []
        self.emotion_labels = ['–£–¥–∏–≤–ª–µ–Ω–∏–µ', '–°—Ç—Ä–∞—Ö', '–û—Ç–≤—Ä–∞—â–µ–Ω–∏–µ', '–†–∞–¥–æ—Å—Ç—å', '–ì—Ä—É—Å—Ç—å', '–ó–ª–æ—Å—Ç—å', '–ë–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ']
        self.history = []
        self.model = None
        self.load_resources()
        self.setup_styles()
        self.create_widgets()
        

    def setup_styles(self):
        self.style = ttk.Style()
        self.style.configure('TFrame', background='#2c3e50')
        self.style.configure('TLabel', background='#2c3e50', foreground='white', font=('Consolas', 10))
        self.style.configure('Title.TLabel', font=('Consolas', 16, 'bold'), foreground='#3498db')
        self.style.configure('TButton', font=('Consolas', 10), padding=10)

    def load_resources(self):
        try:
            model_path = os.path.join('models', 'simplecnn.h5') 
            if os.path.exists(model_path):
                self.model = load_model(model_path)
                if os.path.exists('history.json'):
                    with open('history.json', 'r', encoding='utf-8') as f:
                        self.history = json.load(f)
                print("123")
            else:
                print("345")
        except Exception as e:
            print("856")

    def load_image(self):
        file_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.tiff")]
        )
        if not file_path:
            return

        self.image_path = file_path
        self.face_bboxes = []
        self.emotion_results = []
        self.current_face_index = -1

        # –ë–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∞–Ω–∞–ª–∏–∑–æ–º
        self.detect_btn.config(state='disabled')
        self.analyze_btn.config(state='disabled')
        self.report_btn.config(state='disabled')

        # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.results_text.config(state='normal')
        self.results_text.delete(1.0, tk.END)
        self.results_text.config(state='disabled')

        try:
            from PIL import Image
            pil_img = Image.open(file_path).convert('RGB')
            self.original_image = np.array(pil_img)[:, :, ::-1]  # RGB ‚Üí BGR

            if self.original_image is None or self.original_image.size == 0:
                raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–æ")

            self.processed_image = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
            self.display_image(self.processed_image)

            self.update_status("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            self.detect_btn.config(state='normal')  # –¢–æ–ª—å–∫–æ –∫–Ω–æ–ø–∫–∞ "–ù–∞–π—Ç–∏ –ª–∏—Ü–∞" –∞–∫—Ç–∏–≤–Ω–∞

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:\n{str(e)}")
            self.update_status("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    def create_widgets(self):
        main_container = ttk.Frame(self.root)
        main_container.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)

        title_frame = ttk.Frame(main_container)
        title_frame.pack(fill=tk.X, side=tk.TOP, pady=(0, 20))

        # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç "MoodLens" –ø–æ —Ü–µ–Ω—Ç—Ä—É
        title_label = tk.Label(title_frame, text="MoodLens", 
                            font=("Consolas", 24, "bold"), 
                            fg="#3498db", bg='#2c3e50')
        title_label.pack(expand=True)  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏

        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º grid –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
        content_frame = ttk.Frame(main_container)
        content_frame.pack(fill=tk.BOTH, expand=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ grid –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è - –†–ê–í–ù–´–ï –ß–ê–°–¢–ò
        content_frame.grid_rowconfigure(0, weight=0)  # –í–µ—Ä—Ö–Ω–∏–π —Ä—è–¥ - –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π
        content_frame.grid_rowconfigure(1, weight=1)  # –ù–∏–∂–Ω–∏–π —Ä—è–¥ - —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è
        content_frame.grid_columnconfigure(0, weight=1, uniform="equal")  # –õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ - –†–ê–í–ù–ê–Ø
        content_frame.grid_columnconfigure(1, weight=1, uniform="equal")  # –ü—Ä–∞–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ - –†–ê–í–ù–ê–Ø
        
        # –õ–µ–≤–∞—è –≤–µ—Ä—Ö–Ω—è—è - –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        upload_frame = ttk.LabelFrame(content_frame, text="–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", padding=15)
        upload_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 10), pady=(0, 10))
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–Ω–æ–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ 
        upload_buttons = ttk.Frame(upload_frame)
        upload_buttons.pack(fill=tk.BOTH, expand=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º grid –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∫–∞–∫ –≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
        upload_buttons.grid_columnconfigure(0, weight=1)
        upload_buttons.grid_rowconfigure(0, weight=1)
        
        self.upload_btn = ttk.Button(upload_buttons, text="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–æ—Ç–æ", command=self.load_image)
        self.upload_btn.grid(row=0, column=0, sticky="nsew", padx=5, pady=10)

        # –ü—Ä–∞–≤–∞—è –≤–µ—Ä—Ö–Ω—è—è - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–≤—ã—Ä–æ–≤–Ω–µ–Ω–æ –ø–æ –≤–µ—Ä—Ö—É —Å –∑–∞–≥—Ä—É–∑–∫–æ–π)
        control_frame = ttk.LabelFrame(content_frame, text="–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", padding=15)
        control_frame.grid(row=0, column=1, sticky="nsew", padx=(10, 0), pady=(0, 10))
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–Ω–æ–ø–æ–∫
        control_buttons = ttk.Frame(control_frame)
        control_buttons.pack(fill=tk.BOTH, expand=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º grid –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–Ω–æ–ø–æ–∫
        control_buttons.grid_columnconfigure(0, weight=1)
        control_buttons.grid_columnconfigure(1, weight=1)
        control_buttons.grid_columnconfigure(2, weight=1)
        control_buttons.grid_rowconfigure(0, weight=1)
        
        self.detect_btn = ttk.Button(control_buttons, text="–ù–∞–π—Ç–∏ –ª–∏—Ü–∞", command=self.detect_faces, state='disabled')
        self.detect_btn.grid(row=0, column=0, sticky="nsew", padx=5, pady=10)
        
        self.analyze_btn = ttk.Button(control_buttons, text="–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ª–∏—Ü", command=self.analyze_all_faces, state='disabled')
        self.analyze_btn.grid(row=0, column=1, sticky="nsew", padx=5, pady=10)
        
        self.report_btn = ttk.Button(control_buttons, text="–°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç PDF", command=self.generate_report, state='disabled')
        self.report_btn.grid(row=0, column=2, sticky="nsew", padx=5, pady=10)
        
        # –õ–µ–≤–∞—è –Ω–∏–∂–Ω—è—è - –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä (–±–æ–ª—å—à–∞—è –≤—ã—Å–æ—Ç–∞)
        self.image_frame = ttk.LabelFrame(content_frame, text="–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä", padding=10)
        self.image_frame.grid(row=1, column=0, sticky="nsew", padx=(0, 10), pady=0)
        
        self.canvas = tk.Canvas(self.image_frame, bg='#34495e', highlightthickness=0)
        self.canvas.pack(fill=tk.BOTH, expand=True)
        self.canvas.bind("<Button-1>", self.on_canvas_click)

        # –ü—Ä–∞–≤–∞—è –Ω–∏–∂–Ω—è—è - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ (–±–æ–ª—å—à–∞—è –≤—ã—Å–æ—Ç–∞)
        results_frame = ttk.LabelFrame(content_frame, text="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞", padding=10)
        results_frame.grid(row=1, column=1, sticky="nsew", padx=(10, 0), pady=0)
        
        self.results_text = tk.Text(results_frame, wrap=tk.WORD,
                                bg='#ecf0f1', fg='#2c3e50', font=('Consolas', 10), state='disabled')
        scrollbar = ttk.Scrollbar(results_frame, command=self.results_text.yview)
        self.results_text.config(yscrollcommand=scrollbar.set)
        self.results_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # –°—Ç–∞—Ç—É—Å –±–∞—Ä
        self.status_var = tk.StringVar(value="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ...")
        status_bar = ttk.Label(self.root, textvariable=self.status_var, relief=tk.SUNKEN, anchor=tk.W)
        status_bar.pack(side=tk.BOTTOM, fill=tk.X)
    def update_status(self, message):
            self.status_var.set(message)
        
    def detect_faces(self):
        if self.original_image is None:
            print("!")
            return
        if self.model is None:
            print("1")
            return
        self.update_status("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü...")
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB
            rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
            h, w = rgb.shape[:2]
            self.face_bboxes = []

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º FaceDetection –≤–º–µ—Å—Ç–æ FaceMesh
            with face_detection.FaceDetection(
                model_selection=1,  # 0 ‚Äî –±—ã—Å—Ç—Ä–µ–µ, 1 ‚Äî —Ç–æ—á–Ω–µ–µ
                min_detection_confidence=0.3
            ) as fd:
                results = fd.process(rgb)

            if not results.detections:
                messagebox.showinfo("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "–õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                self.update_status("–õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                return

            for detection in results.detections:
                # –ü–æ–ª—É—á–∞–µ–º bounding box
                bbox = detection.location_data.relative_bounding_box
                x_min = int(bbox.xmin * w)
                y_min = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                self.face_bboxes.append((x_min, y_min, width, height))

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_with_faces = self.processed_image.copy()
            
            colors = [
                (0, 255, 0),    # –ó–µ–ª—ë–Ω—ã–π
                (255, 0, 0),    # –ö—Ä–∞—Å–Ω—ã–π
                (0, 0, 255),    # –°–∏–Ω–∏–π
                (255, 255, 0),  # –ì–æ–ª—É–±–æ–π
                (255, 0, 255),  # –ü—É—Ä–ø—É—Ä–Ω—ã–π
                (0, 255, 255),  # –ñ—ë–ª—Ç—ã–π
                (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π
            ]

            for i, (x, y, w_box, h_box) in enumerate(self.face_bboxes):
                color = colors[i % len(colors)]  # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º —Ü–≤–µ—Ç
                cv2.rectangle(img_with_faces, (x, y), (x + w_box, y + h_box), color, 2)
                cv2.putText(img_with_faces, f'Face {i+1}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            self.display_image(img_with_faces)
            self.update_status(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {len(self.face_bboxes)}")
            self.analyze_btn.config(state='normal')

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {str(e)}")
            self.update_status("–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ª–∏—Ü")
    def on_canvas_click(self, event):
        if not self.face_bboxes:
            return

        x_click = (event.x - self.canvas_offset_x) / self.scale_factor
        y_click = (event.y - self.canvas_offset_y) / self.scale_factor

        for i, (x, y, w, h) in enumerate(self.face_bboxes):
            if x <= x_click <= x + w and y <= y_click <= y + h:
                self.current_face_index = i
                self.highlight_selected_face()
                self.update_status(f"–í—ã–±—Ä–∞–Ω–æ –ª–∏—Ü–æ {i+1}")
                break

    def highlight_selected_face(self):
        if self.current_face_index == -1:
            return

        img_highlight = self.processed_image.copy()
        for i, (x, y, w, h) in enumerate(self.face_bboxes):
            color = (0, 255, 255) if i == self.current_face_index else (255, 0, 0)
            thickness = 3 if i == self.current_face_index else 2
            cv2.rectangle(img_highlight, (x, y), (x + w, y + h), color, thickness)
            cv2.putText(img_highlight, f'Face {i+1}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.5 if i != self.current_face_index else 0.6, color, thickness)

        self.display_image(img_highlight)

    def display_image(self, image):
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã canvas
        canvas_w = self.canvas.winfo_width()
        canvas_h = self.canvas.winfo_height()
        
        if canvas_w <= 0 or canvas_h <= 0:
            canvas_w = 600
            canvas_h = 500
        
        h, w = image.shape[:2]
        scale = min(canvas_w / w, canvas_h / h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        resized = cv2.resize(image, (new_w, new_h))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image –¥–ª—è tkinter
        pil_image = Image.fromarray(resized)
        self.photo = ImageTk.PhotoImage(pil_image)
        
        # –û—á–∏—â–∞–µ–º canvas –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        self.canvas.delete("all")
        self.canvas.create_image(canvas_w // 2, canvas_h // 2, image=self.photo, anchor=tk.CENTER)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        self.scale_factor = scale
        self.canvas_offset_x = (canvas_w - new_w) // 2
        self.canvas_offset_y = (canvas_h - new_h) // 2
    def analyze_all_faces(self):
        if not self.face_bboxes or self.model is None:
            return

        self.update_status("–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ª–∏—Ü...")
        self.emotion_results = []

        # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–¥ –Ω–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        self.results_text.config(state='normal')
        self.results_text.delete(1.0, tk.END)

        try:
            for i, (x, y, w, h) in enumerate(self.face_bboxes):
                face_roi = self.original_image[y:y+h, x:x+w]
                if face_roi.size == 0:
                    continue

                face_gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
                face_resized = cv2.resize(face_gray, (48, 48))
                face_input = face_resized.astype('float32') / 255.0
                face_input = np.expand_dims(face_input, axis=(0, -1))

                pred = self.model.predict(face_input, verbose=0)[0]
                result = {
                    'face_index': i,
                    'coordinates': (x, y, w, h),
                    'emotions': {self.emotion_labels[j]: float(pred[j]) for j in range(len(self.emotion_labels))},
                    'dominant_emotion': self.emotion_labels[int(np.argmax(pred))],
                    'dominant_prob': float(np.max(pred)) * 100,
                    'analysis_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'image_path': self.image_path,
                    'id': str(uuid.uuid4())
                }
                self.emotion_results.append(result)
                self.display_results(result)  # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç

            if self.emotion_results:
                self.current_face_index = 0
                self.report_btn.config(state='normal')
            self.update_status(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(self.emotion_results)} –ª–∏—Ü")
            self.history.extend(self.emotion_results)
            with open('history.json', 'w', encoding='utf-8') as f:
                json.dump(self.history, f, indent=2, ensure_ascii=False)

            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë–º PDF-–æ—Ç—á—ë—Ç
            self.auto_generate_report()

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
            self.update_status("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π")

        finally:
            # –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–µ –ø–æ—Å–ª–µ –≤—ã–≤–æ–¥–∞
            self.results_text.config(state='disabled')
    def auto_generate_report(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë—Ç PDF-–æ—Ç—á—ë—Ç –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø—É—Ç–∏"""
        if not self.emotion_results:
            return

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç—ã –∏ –∏–º–µ–Ω–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{os.path.splitext(os.path.basename(self.image_path))[0]}_{timestamp}.pdf"
        file_path = os.path.join('reports', filename)

        os.makedirs('reports', exist_ok=True)

        try:
            self.update_status("–°–æ–∑–¥–∞–Ω–∏–µ PDF –æ—Ç—á–µ—Ç–∞...")

            # –ï–¥–∏–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –ê4
            FIG_WIDTH = 11.69   # –¥—é–π–º—ã
            FIG_HEIGHT = 8.27   # –¥—é–π–º—ã
            DPI = 150           # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–µ—á–∞—Ç–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

            emotions_list = ['–£–¥–∏–≤–ª–µ–Ω–∏–µ', '–°—Ç—Ä–∞—Ö', '–û—Ç–≤—Ä–∞—â–µ–Ω–∏–µ', '–†–∞–¥–æ—Å—Ç—å', '–ì—Ä—É—Å—Ç—å', '–ó–ª–æ—Å—Ç—å', '–ë–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ']
            colors = ['#e74c3c', '#e67e22', '#f1c40f', '#2ecc71', '#95a5a6', '#3498db', '#9b59b6']

            with PdfPages(file_path) as pdf:
                def save_figure_horizontal(fig):
                    pdf.savefig(fig, bbox_inches=None, pad_inches=0, dpi=300)
                    plt.close(fig)

                # === 1. –¢–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ===
                fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))
                plt.subplots_adjust(left=0.1, right=0.9, top=0.85, bottom=0.15)
                ax.axis('off')
                ax.text(0.5, 0.6, 'MoodLens - –û—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π', fontsize=20, fontweight='bold', ha='center')
                ax.text(0.5, 0.4, f'–î–∞—Ç–∞: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', fontsize=14, ha='center')
                ax.text(0.5, 0.3, f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {os.path.basename(self.image_path)}', fontsize=12, ha='center')
                save_figure_horizontal(fig)

                fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))
                plt.subplots_adjust(left=0.1, right=0.9, top=0.85, bottom=0.15)
                ax.axis('off')

                img_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
                if img_rgb.dtype != np.uint8:
                    img_rgb = img_rgb.astype(np.uint8)

                img_h, img_w = img_rgb.shape[:2]

                max_img_width_inch = 0.6 * FIG_WIDTH
                max_img_height_inch = 0.5 * FIG_HEIGHT

                max_img_width_px = int(max_img_width_inch * 300)
                max_img_height_px = int(max_img_height_inch * 300)

                scale = min(1.0, max_img_width_px / img_w, max_img_height_px / img_h)
                new_w = int(img_w * scale)
                new_h = int(img_h * scale)

                from PIL import Image as PILImage
                pil_img = PILImage.fromarray(img_rgb)
                pil_img = pil_img.resize((new_w, new_h), PILImage.LANCZOS)
                img_display = np.array(pil_img)

                ax.imshow(img_display, interpolation='none', cmap='gray')
                ax.set_title(f'–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n({len(self.face_bboxes)} –ª–∏—Ü –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ)', 
                            fontsize=14, pad=20, ha='center')

                for i, (x, y, w, h) in enumerate(self.face_bboxes):
                    x_scaled = x * scale
                    y_scaled = y * scale
                    w_scaled = w * scale
                    h_scaled = h * scale
                    
                    rect = plt.Rectangle((x_scaled, y_scaled), w_scaled, h_scaled, 
                                        fill=False, color='red', linewidth=2)
                    ax.add_patch(rect)
                    ax.text(x_scaled, y_scaled - 8, f'Face {i+1}', color='red', fontsize=10,
                            bbox=dict(facecolor='white', alpha=0.8))

                ax.set_xticks([])
                ax.set_yticks([])

                save_figure_horizontal(fig)

                # –ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ª–∏—Ü—É ===
                for result in self.emotion_results:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(FIG_WIDTH, FIG_HEIGHT))
                    plt.subplots_adjust(left=0.08, right=0.95, top=0.85, bottom=0.15, wspace=0.3)

                    sorted_emotions = sorted(result['emotions'].items(), key=lambda x: x[1], reverse=True)
                    sorted_labels = [item[0] for item in sorted_emotions]
                    sorted_probs = [item[1] * 100 for item in sorted_emotions]
                    sorted_colors = [colors[emotions_list.index(label)] for label in sorted_labels]

                    bars = ax1.bar(sorted_labels, sorted_probs, color=sorted_colors, alpha=0.7, width=0.6)
                    ax1.set_title(f'–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –ª–∏—Ü–∞ {result["face_index"] + 1}', fontsize=16, pad=15)
                    ax1.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)', fontsize=12)
                    ax1.set_ylim(0, 100)
                    ax1.tick_params(axis='x', labelsize=10, rotation=45)
                    ax1.tick_params(axis='y', labelsize=10)
                    ax1.set_xticklabels(sorted_labels, rotation=45, ha='right')
                    for bar, prob in zip(bars, sorted_probs):
                        ax1.text(bar.get_x() + bar.get_width()/2., min(prob + 2, 98),
                                f'{prob:.1f}%', ha='center', va='bottom', fontsize=9)

                    ax2.axis('off')
                    table_data = [[emotion, f"{prob*100:.1f}%"] for emotion, prob in sorted_emotions]
                    table = ax2.table(cellText=table_data,
                                    colLabels=['–≠–º–æ—Ü–∏—è', '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'],
                                    cellLoc='center',
                                    loc='center',
                                    bbox=[0.1, 0.1, 0.8, 0.8])
                    table.auto_set_font_size(False)
                    table.set_fontsize(10)
                    table.scale(1, 1.5)
                    ax2.set_title('–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', fontsize=16, pad=15)

                    save_figure_horizontal(fig)

            self.update_status(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {str(e)}")
            self.update_status("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞")
    def display_results(self, result):
        # –í–∫–ª—é—á–∞–µ–º –Ω–∞ –∑–∞–ø–∏—Å—å
        self.results_text.config(state='normal')

        self.results_text.insert(tk.END, f"–ê–Ω–∞–ª–∏–∑ –ª–∏—Ü–∞ {result['face_index'] + 1}\n")
        self.results_text.insert(tk.END, "\n")
        self.results_text.insert(tk.END, f"–î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {result['dominant_emotion']}\n")
        self.results_text.insert(tk.END, f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['dominant_prob']:.1f}%\n\n")
        self.results_text.insert(tk.END, "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π:\n")

        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –º–µ—Ç–∫–∏ (–¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è)
        max_label_len = max(len(emotion) for emotion in result['emotions'].keys())
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        sorted_emotions = sorted(result['emotions'].items(), key=lambda x: x[1], reverse=True)

        for emotion, prob in sorted_emotions:
            prob_str = f"{prob*100:5.1f}"  # 5.1f ‚Üí " 83.8" (5 —Å–∏–º–≤–æ–ª–æ–≤)
            bar = "‚ñà" * int(prob * 100 / 5)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º
            label_part = f"{emotion}:"
            padding = " " * (max_label_len - len(emotion) + 1)  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è

            self.results_text.insert(tk.END, f"{label_part}{padding}{prob_str}% {bar}\n")

        self.results_text.insert(tk.END, "\n")

        # –û–ø—è—Ç—å –±–ª–æ–∫–∏—Ä—É–µ–º
        self.results_text.config(state='disabled')
    def generate_report(self):
        if not self.emotion_results:
            messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞")
            return

        file_path = filedialog.asksaveasfilename(
            title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç PDF",
            defaultextension=".pdf",
            filetypes=[("PDF files", "*.pdf")]
        )
        if not file_path:
            return

        try:
            self.update_status("–°–æ–∑–¥–∞–Ω–∏–µ PDF –æ—Ç—á–µ—Ç–∞...")

            # –ï–¥–∏–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –ê4
            FIG_WIDTH = 11.69   # –¥—é–π–º—ã
            FIG_HEIGHT = 8.27   # –¥—é–π–º—ã
            DPI = 150           # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–µ—á–∞—Ç–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

            emotions_list = ['–£–¥–∏–≤–ª–µ–Ω–∏–µ', '–°—Ç—Ä–∞—Ö', '–û—Ç–≤—Ä–∞—â–µ–Ω–∏–µ', '–†–∞–¥–æ—Å—Ç—å', '–ì—Ä—É—Å—Ç—å', '–ó–ª–æ—Å—Ç—å', '–ë–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ']
            colors = ['#e74c3c', '#e67e22', '#f1c40f', '#2ecc71', '#95a5a6', '#3498db', '#9b59b6']

            with PdfPages(file_path) as pdf:
                def save_figure_horizontal(fig):
                    # –í–ê–ñ–ù–û: bbox_inches=None –∏ pad_inches=0 ‚Äî —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    pdf.savefig(fig, bbox_inches=None, pad_inches=0, dpi=300)  # –∏–ª–∏ 200, 150 ‚Äî –ø–æ –∂–µ–ª–∞–Ω–∏—é                    plt.close(fig)

                # === 1. –¢–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ===
                fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))
                plt.subplots_adjust(left=0.1, right=0.9, top=0.85, bottom=0.15)
                ax.axis('off')
                ax.text(0.5, 0.6, 'MoodLens - –û—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π', fontsize=20, fontweight='bold', ha='center')
                ax.text(0.5, 0.4, f'–î–∞—Ç–∞: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', fontsize=14, ha='center')
                ax.text(0.5, 0.3, f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {os.path.basename(self.image_path)}', fontsize=12, ha='center')
                save_figure_horizontal(fig)

                            # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º 
                fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT))
                plt.subplots_adjust(left=0.1, right=0.9, top=0.85, bottom=0.15)
                ax.axis('off')

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                img_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
                if img_rgb.dtype != np.uint8:
                    img_rgb = img_rgb.astype(np.uint8)

                img_h, img_w = img_rgb.shape[:2]

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤ –¥—é–π–º–∞—Ö)
                max_img_width_inch = 0.6 * FIG_WIDTH   # 60% —à–∏—Ä–∏–Ω—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                max_img_height_inch = 0.5 * FIG_HEIGHT # 50% –≤—ã—Å–æ—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã

                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ –ø–∏–∫—Å–µ–ª–∏ –ø—Ä–∏ DPI=300 (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞)
                max_img_width_px = int(max_img_width_inch * 300)
                max_img_height_px = int(max_img_height_inch * 300)

                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –£–ú–ï–ù–¨–®–ò–¢–¨ (–Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º!)
                scale = min(1.0, max_img_width_px / img_w, max_img_height_px / img_h)
                new_w = int(img_w * scale)
                new_h = int(img_h * scale)

                # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ PIL
                from PIL import Image as PILImage
                pil_img = PILImage.fromarray(img_rgb)
                pil_img = pil_img.resize((new_w, new_h), PILImage.LANCZOS)
                img_display = np.array(pil_img)

                ax.imshow(img_display, interpolation='none', cmap='gray')

                ax.set_title(f'–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n', 
                            fontsize=14, pad=20, ha='center')

                # –†–∏—Å—É–µ–º bounding boxes
                for i, (x, y, w, h) in enumerate(self.face_bboxes):
                    x_scaled = x * scale
                    y_scaled = y * scale
                    w_scaled = w * scale
                    h_scaled = h * scale
                    
                    rect = plt.Rectangle((x_scaled, y_scaled), w_scaled, h_scaled, 
                                        fill=False, color='red', linewidth=2)
                    ax.add_patch(rect)
                    ax.text(x_scaled, y_scaled - 8, f'Face {i+1}', color='red', fontsize=10,
                            bbox=dict(facecolor='white', alpha=0.8))

                # –£–±–∏—Ä–∞–µ–º –æ—Å–∏
                ax.set_xticks([])
                ax.set_yticks([])

                save_figure_horizontal(fig)
                # –ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ª–∏—Ü—É ===
                for result in self.emotion_results:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(FIG_WIDTH, FIG_HEIGHT))
                    plt.subplots_adjust(left=0.08, right=0.95, top=0.85, bottom=0.15, wspace=0.3)

                    sorted_emotions = sorted(result['emotions'].items(), key=lambda x: x[1], reverse=True)
                    sorted_labels = [item[0] for item in sorted_emotions]
                    sorted_probs = [item[1] * 100 for item in sorted_emotions]
                    sorted_colors = [colors[emotions_list.index(label)] for label in sorted_labels]

                    # –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
                    bars = ax1.bar(sorted_labels, sorted_probs, color=sorted_colors, alpha=0.7, width=0.6)
                    ax1.set_title(f'–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –ª–∏—Ü–∞ {result["face_index"] + 1}', fontsize=16, pad=15)
                    ax1.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)', fontsize=12)
                    ax1.set_ylim(0, 100)
                    ax1.tick_params(axis='x', labelsize=10, rotation=45)
                    ax1.tick_params(axis='y', labelsize=10)
                    ax1.set_xticklabels(sorted_labels, rotation=45, ha='right')
                    for bar, prob in zip(bars, sorted_probs):
                        ax1.text(bar.get_x() + bar.get_width()/2., min(prob + 2, 98),
                                f'{prob:.1f}%', ha='center', va='bottom', fontsize=9)

                    # –¢–∞–±–ª–∏—Ü–∞
                    ax2.axis('off')
                    table_data = [[emotion, f"{prob*100:.1f}%"] for emotion, prob in sorted_emotions]
                    table = ax2.table(cellText=table_data,
                                    colLabels=['–≠–º–æ—Ü–∏—è', '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'],
                                    cellLoc='center',
                                    loc='center',
                                    bbox=[0.1, 0.1, 0.8, 0.8])
                    table.auto_set_font_size(False)
                    table.set_fontsize(10)
                    table.scale(1, 1.5)
                    ax2.set_title('–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', fontsize=16, pad=15)

                    save_figure_horizontal(fig)

            self.update_status(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")
            messagebox.showinfo("–£—Å–ø–µ—Ö", f"PDF –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω!\n{file_path}")

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {str(e)}")
            self.update_status("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞")
def main():
    os.makedirs('reports', exist_ok=True)
    root = tk.Tk()
    app = EmotionRecognitionApp(root)
    root.mainloop()

if __name__ == "__main__":
    main()